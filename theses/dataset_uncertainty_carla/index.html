<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A new benchmark for anomaly segmentation in driving scenes. | Carlo Masone </title> <meta name="author" content="Carlo Masone"> <meta name="description" content="A new benchmark for anomaly segmentation in driving scenes."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/my_icon.png?dd27a82351df81a65f9fc1dac22bddb7"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cmas1.github.io/theses/dataset_uncertainty_carla/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Carlo</span> Masone </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">people </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/phd_students/">phd students</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/master_students/">master students</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/collaborators/">collaborators</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">open positions </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/theses/">theses</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/phd_positions/">phd positions</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/senior%20positions/">senior positions</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">A new benchmark for anomaly segmentation in driving scenes.</h1> <p class="post-description">A new benchmark for anomaly segmentation in driving scenes.</p> </header> <article> <h4 id="supervision">Supervision</h4> <p>The thesis will be supervised by and performed with the Visual and Multimodal lab (<a href="https://vandal.polito.it/" rel="external nofollow noopener" target="_blank">VANDAL</a>) @ Politecnico di Torino. The VANDAL lab is an excellence research lab for Machine Learning and Computer Vision, both for theoretical and application-driven problems (e.g., in Robotics, Industry 4.0+, Autonomous Driving, etc.). VANDAL is part of the European Laboratory for Learning and Intelligent Systems (<a href="https://ellis.eu/" rel="external nofollow noopener" target="_blank">ELLIS</a>), a European Network of the top research institutions in AI.</p> <h4 id="guidance-and-contacts">Guidance and contacts</h4> <ul> <li> <strong>Carlo Masone</strong>: carlo.masone@polito.it</li> <li> <strong>Tatiana Tommasi</strong>: tatiana.tommasi@polito.it</li> </ul> <h4 id="number-of-positions">Number of Positions</h4> <p><strong>Up to 3 students</strong>.</p> <h4 id="context">Context</h4> <p>In recent years the automotive industry has been heavily investing in AI, causing a profound shift in the future of automobiles. Considering the complexity of driving environments, where there is a multitude of scenes and unpredictable dynamic elements, model-based approaches inevitably are not enough, and data-driven solution hold the promise of enabling a new breed of algorithms that can increase the safety and autonomy of vehicles.</p> <p>Perception, and more specifically understanding the intricacies of the scene surrounding the vehicle only using its onboard sensors, is one of the most difficult tasks, one with many open problems and room for improvements. To develop more advanced assistive functionalities and even future autonomous vehicles, we must be able to finely detect, classify and localize all the elements in the vehicle’s surroundings. That is the reason why segmentation approaches are widely researched and developed for driving applications, and some of the most notorious open-source semantic segmentation datasets come from this application domain (e.g., Cityscapes [1], BDD100K [2], Indian Driving Dataset [3], ApolloScape [4], …).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/theses/dataset_uncertainty_carla/semseg_examples-480.webp 480w,/assets/img/theses/dataset_uncertainty_carla/semseg_examples-800.webp 800w,/assets/img/theses/dataset_uncertainty_carla/semseg_examples-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/theses/dataset_uncertainty_carla/semseg_examples.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="examples of semantic segmentation in driving scenes" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 1.</b> Examples of semantic segmentation from Cityscapes, BDD100k, Indian Driving Simulator. </div> <p>The ability to finely segment and comprehend the vehicle surroundings is critical to identify driveable spaces, static and dynamic agents, and ultimately it is a step that is essential to create a local map of the vehicle which can be used for maneuver and motion planning. Yet, considering the safety critical nature of the application, these segmentation algorithms must be judged not only by the accuracy of their predictions, but also by the degree of certainty of those predictions and their capability to identify anomalies.</p> <p><strong>Anomaly segmentation</strong> is the term that denotes the task of precisely (pixel-wise) segmenting anomalies, i.e., patterns and elements which deviate from the normality. This is an important focus in research and driving applications, as demonstrated by the numerous recent publications [5-8] and workshops/events organized at the major conferences with industrial sponsorships [9-10].</p> <h4 id="goal">Goal</h4> <p>Currently, there are few benchmarks available specifically for anomaly segmentation in driving scenes: FishyScapes, SegmentMeIfYouCan (SMIYC) and RoadAnomaly. These datasets contain real or synthetic images collected from a monocular camera and generally represent anomalies/obstacles as new (i.e., unseen during training) things on the road. Yet, there are a few problems with these benchmarks:</p> <ul> <li>They have a narrow concept of what an anomaly is. Namely, they consider as anomalies new objects unseen during training, mostly placed on the street. Yet, the notion of anomaly is more general, as something that is not in the normal way of operation. For example, an anomaly could also be an instance of an object category seen during training, but in a strange configuration (e.g., a fallen tree).</li> <li>Since anomalies in these benchmarks are new classes, most anomaly segmentation methods at the top of these leaderboards are fine-tuned with supervision obtained by artificially pasting new objects on the training data and using them as anomalies. Yet, we would like to go towards unsupervised solutions that simply rely on the notion of something that goes beyond the normality.</li> <li>They have a single modality (RGB camera) and do not really allow to explore different sensor modalities (e.g., point-cloud, depth, …).</li> <li>They do not consider temporal information, whereas cars they acquire continuous streams of data.</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/theses/dataset_uncertainty_carla/anomaly_segmentation_example-480.webp 480w,/assets/img/theses/dataset_uncertainty_carla/anomaly_segmentation_example-800.webp 800w,/assets/img/theses/dataset_uncertainty_carla/anomaly_segmentation_example-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/theses/dataset_uncertainty_carla/anomaly_segmentation_example.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="examples of anomalies from SegmentMeIfYouCan" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 2.</b> Examples of anomalies from the <a href="https://segmentmeifyoucan.com/" rel="external nofollow noopener" target="_blank">SegmentMeIfYouCan</a> benchmark. </div> <p>The goal of this thesis is to address these limitations, by creating a new dataset and benchmark that is more representative of general anomalies and that contains data from multiple sensor modalities. The datasets will be created using the open source CARLA simulator and it will be used to test existing methods, to gain new insights on their limitations and to go towards purely unsupervised solutions.</p> <h4 id="methodology">Methodology</h4> <p>The plan is to use the open-source simulator <a href="https://carla.org//" rel="external nofollow noopener" target="_blank">CARLA</a>. This is the most notorious open-source driving simulator available, and it constantly used as a test bench for challenges at the top conferences in computer vision, robotics and artificial intelligence (e.g., at <a href="https://opendrivelab.com/challenge2024/#carla" rel="external nofollow noopener" target="_blank">CVPR 2024</a> ). The simulator itself builds upon the Unreal engine (currently the version 4.0, but they are upgrading to the 5.0 version), which allows to have high quality graphics and realistic dynamics.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/theses/dataset_uncertainty_carla/screenshots_carla-480.webp 480w,/assets/img/theses/dataset_uncertainty_carla/screenshots_carla-800.webp 800w,/assets/img/theses/dataset_uncertainty_carla/screenshots_carla-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/theses/dataset_uncertainty_carla/screenshots_carla.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="screenshots from the CARLA simulator" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption">Screenshots from the <a href="https://carla.org//" rel="external nofollow noopener" target="_blank">CARLA</a> simulator. </div> <p>The simulator provides several functionalities and assets already implemented, including maps, vehicles and pedestrian agents, sensors (cameras, lidars, radars, event cameras), the ability to change weather conditions and many other parameters in the simulation. A python API allows to easily interact with the simulation.</p> <p>The first and major part of the thesis will be devoted to the creation of the dataset. This implies not only using the Python scripts already packaged with CARLA, but it will require modification of the underlying Unreal scenes, to insert anomalies. The second part of the thesis will involve testing a variety of segmentation algorithms available in literature on the newly collected data. In particular, we aim to have at least algorithms working with RGB images and algorithm for point-clouds. If more students select this thesis at the same time, they are expected to work together on the dataset creation and perhaps differentiate their works by testing different algorithms or by focusing on different aspects (e.g., different sensor modalities or different weather/illumination conditions).</p> <p><em><strong>The dataset and benchmark have the potential to become a publication and impact this field of research, which is potentially of interest to companies as well.</strong></em></p> <h4 id="references">References</h4> <p>[1] M. Cordts et al., “The Cityscapes Dataset for Semantic Urban Scene Understanding”, IEEE/CVF CVPR 2016</p> <p>[2] F. Yu et al., “BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning”, IEEE/CVF CVPR 2020</p> <p>[3] C. Parikh et al., “IDD-X: A Multi-View Dataset for Ego-relative Important Object Localization and Explanation in Dense and Unstructured Traffic”, IEEE ICRA 2024</p> <p>[4] X. Huang et al., “The ApolloScape Open Dataset for Autonomous Driving and its Application”, IEEE T-PAMI 2020</p> <p>[5] S. Nandan Rai et al., “Mask2Anomaly: Mask Transformer for Universal Open-set Segmentation”, IEEE T-PAMI 2024</p> <p>[6] N. Nayal et al., “RbA: Segmenting unknown regions rejected by all”, IEEE/CVF ICCV 2023</p> <p>[7] J. Ackermann et al., “Maskomaly: Zeroshot mask anomaly segmentation”, BMVC 2023</p> <p>[8] M. Grcic et al., “On advantages of mask-level recognition for outlier-aware segmentation”, IEEE/CVF ICCV-W 2023</p> <p>[9] <a href="https://sites.google.com/view/roameccv2024/" rel="external nofollow noopener" target="_blank">ROAM: Robust, Out-of-Distribution And Multi-Modal models for Autonomous Driving</a>, ECCV 2024</p> <p>[10] <a href="https://sites.google.com/view/road-eccv2024/home" rel="external nofollow noopener" target="_blank">ROAD++: The Third Workshop &amp; Challenge: Event Detection for Situation Awareness in Autonomous Driving</a>, ECCV 2024</p> <p>[11] H. Blum et al., <a href="https://fishyscapes.com/" rel="external nofollow noopener" target="_blank">The Fishyscapes Benchmark: Measuring Blind Spots in Semantic Segmentation</a>, IJCV 2021</p> <p>[12] R. Chan et al., <a href="https://segmentmeifyoucan.com/" rel="external nofollow noopener" target="_blank">SegmentMeIfYouCan: A Benchmark for Anomaly Segmentation</a>, NeurIPS 2021</p> <p>[13] K. Lis et al., “Detecting the Unexpected via Image Resynthesis”, IEEE/CVF ICCV 2019</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Carlo Masone. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-research",title:"research",description:"A brief summary of my present and past research.",section:"Navigation",handler:()=>{window.location.href="/research/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"Brief Curriculum Vitae. For the extended version, please check the pdf version.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-repositories",title:"repositories",description:"Repositories and software libraries.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"dropdown-phd-students",title:"phd students",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-master-students",title:"master students",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-collaborators",title:"collaborators",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-theses",title:"theses",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-phd-positions",title:"phd positions",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-senior-positions",title:"senior positions",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"nav-teaching",title:"teaching",description:"Teaching and courses.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/05/01/tabs.html"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/04/29/typograms.html"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/04/28/post-citation.html"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/04/15/pseudocode.html"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/01/27/code-diff.html"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/01/27/advanced-images.html"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/01/27/vega-lite.html"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/01/26/geojson-map.html"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/01/26/echarts.html"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2024/01/26/chartjs.html"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/12/12/tikzjax.html"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/07/12/post-bibliography.html"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/07/04/jupyter-notebook.html"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/05/12/custom-blockquotes.html"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/04/25/sidebar-table-of-contents.html"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/04/25/audios.html"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/04/24/videos.html"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/03/20/tables.html"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/sample-posts/2023/03/20/table-of-contents.html"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/sample-posts/external-services/2022/12/10/giscus-comments.html"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/2021/07/04/diagrams.html"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/2021/05/22/distill.html"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/sample-posts/external-services/2020/09/28/twitter.html"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/sample-posts/external-services/2015/10/20/disqus-comments.html"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/sample-posts/2015/10/20/math.html"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/sample-posts/2015/07/15/code.html"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/sample-posts/2015/05/15/images.html"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/sample-posts/2015/03/15/formatting-and-links.html"}},{id:"news-trophy-i-have-been-nominated-as-an-outstanding-reviewer-for-cvpr-2024-third-year-in-a-row-open-mouth",title:'<img class="emoji" title=":trophy:" alt=":trophy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c6.png" height="20" width="20"> I have been nominated as an Outstanding Reviewer for CVPR 2024! Third...',description:"",section:"News"},{id:"news-scroll-our-paper-mask2anomaly-mask-transformer-for-universal-open-set-segmentation-was-accepted-to-ieee-transactions-on-pattern-analysis-and-machine-intelligence-kudos-to-shyam-nandan-rai-for-the-achievement",title:'<img class="emoji" title=":scroll:" alt=":scroll:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4dc.png" height="20" width="20"> Our paper Mask2Anomaly: Mask Transformer for Universal Open-set Segmentation was accepted to...',description:"",section:"News"},{id:"news-star-for-the-second-year-in-a-row-i-am-serving-as-area-chair-for-the-wacv-conference",title:'<img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"> For the second year in a row, I am serving as Area...',description:"",section:"News"},{id:"news-scroll-our-paper-meshvpr-citywide-visual-place-recognition-using-3d-meshes-was-accepted-to-eccv-2024-check-out-the-project-page",title:'<img class="emoji" title=":scroll:" alt=":scroll:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4dc.png" height="20" width="20"> Our paper MeshVPR: Citywide Visual Place Recognition Using 3D Meshes was accepted...',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"research-cooperative-aerial-transportation",title:"Cooperative Aerial Transportation",description:"a cable-suspended payload transported by a team of micro UAVs",section:"Research",handler:()=>{window.location.href="/research/aerial_cable/"}},{id:"research-cablerobot-simulator",title:"CableRobot Simulator",description:"world's first cable robot for passengers",section:"Research",handler:()=>{window.location.href="/research/cable_robot/"}},{id:"research-continuous-kernels-learning",title:"Continuous kernels learning",description:"Coming soon.",section:"Research",handler:()=>{window.location.href="/research/continuous_function/"}},{id:"research-cybermotion-simulator",title:"CyberMotion Simulator",description:"a motion simulator based on an industrial robot arm",section:"Research",handler:()=>{window.location.href="/research/cyber_motion/"}},{id:"research-distributed-learning",title:"Distributed learning",description:"(Learn) One for all, and all for one.",section:"Research",handler:()=>{window.location.href="/research/distributed/"}},{id:"research-edge-ai",title:"Edge AI",description:"Coming soon.",section:"Research",handler:()=>{window.location.href="/research/edge_AI/"}},{id:"research-localization",title:"Localization",description:"Where am I? Where is everything else?",section:"Research",handler:()=>{window.location.href="/research/localization/"}},{id:"research-reliable-machine-learning",title:"Reliable machine learning",description:"Sorry, the AI is out of order. Please call the technician.",section:"Research",handler:()=>{window.location.href="/research/reliable_learning/"}},{id:"research-robust-control-of-robotic-platforms",title:"Robust Control of Robotic Platforms",description:"sliding mode controllers for robotic platforms",section:"Research",handler:()=>{window.location.href="/research/robust_control/"}},{id:"research-shared-control-and-planning-of-uavs",title:"Shared Control and Planning of UAVs",description:"control and planning algorithms for UAVs, whose execution is interfaced with a human operator.",section:"Research",handler:()=>{window.location.href="/research/shared_control/"}},{id:"research-fine-grained-visual-understanding",title:"Fine grained visual understanding",description:"from patch-level to pixel-level details",section:"Research",handler:()=>{window.location.href="/research/visual_understanding/"}},{id:"software-holorlib",title:"HolorLib",description:"A C++20 header-only library for generic multi-dimensional containers.",section:"Software",handler:()=>{window.location.href="/software/holorlib/"}},{id:"theses-a-new-benchmark-for-anomaly-segmentation-in-driving-scenes",title:"A new benchmark for anomaly segmentation in driving scenes.",description:"A new benchmark for anomaly segmentation in driving scenes.",section:"Theses",handler:()=>{window.location.href="/theses/dataset_uncertainty_carla/"}},{id:"theses-3d-scene-reconstruction-and-novel-view-synthesis-with-gaussian-splatting",title:"3D scene reconstruction and novel view synthesis with Gaussian Splatting.",description:"3D scene reconstruction.",section:"Theses",handler:()=>{window.location.href="/theses/gaussian_splatting/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%61%72%6C%6F.%6D%61%73%6F%6E%65@%70%6F%6C%69%74%6F.%69%74","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-1609-9338","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=cM3Iz_4AAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Carlo-Masone/","_blank")}},{id:"socials-scopus",title:"Scopus",section:"Socials",handler:()=>{window.open("https://www.scopus.com/authid/detail.uri?authorId=36463980500","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/cmas1","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/cmasone","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/masone_carlo","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>